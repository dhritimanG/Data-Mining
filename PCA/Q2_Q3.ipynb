{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar 20 00:28:16 2018\n",
    "\n",
    "@author: dhritiman\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import gzip\n",
    "import struct\n",
    "import array\n",
    "import tempfile\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve  # py2\n",
    "try:\n",
    "    from urllib.parse import urljoin\n",
    "except ImportError:\n",
    "    from urlparse import urljoin\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the url can be changed by the users of the library (not a constant)\n",
    "datasets_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "\n",
    "class IdxDecodeError(ValueError):\n",
    "    \"\"\"Raised when an invalid idx file is parsed.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_file(fname, target_dir=None, force=False):\n",
    "    \"\"\"Download fname from the datasets_url, and save it to target_dir,\n",
    "    unless the file already exists, and force is False.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Name of the file to download\n",
    "\n",
    "    target_dir : str\n",
    "        Directory where to store the file\n",
    "\n",
    "    force : bool\n",
    "        Force downloading the file, if it already exists\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fname : str\n",
    "        Full path of the downloaded file\n",
    "    \"\"\"\n",
    "    if not target_dir:\n",
    "        target_dir = tempfile.gettempdir()\n",
    "    target_fname = os.path.join(target_dir, fname)\n",
    "\n",
    "    if force or not os.path.isfile(target_fname):\n",
    "        url = urljoin(datasets_url, fname)\n",
    "        urlretrieve(url, target_fname)\n",
    "\n",
    "    return target_fname\n",
    "\n",
    "\n",
    "def parse_idx(fd):\n",
    "    \"\"\"Parse an IDX file, and return it as a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fd : file\n",
    "        File descriptor of the IDX file to parse\n",
    "\n",
    "    endian : str\n",
    "        Byte order of the IDX file. See [1] for available options\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : numpy.ndarray\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "\n",
    "    1. https://docs.python.org/3/library/struct.html#byte-order-size-and-alignment\n",
    "    \"\"\"\n",
    "    DATA_TYPES = {0x08: 'B',  # unsigned byte\n",
    "                  0x09: 'b',  # signed byte\n",
    "                  0x0b: 'h',  # short (2 bytes)\n",
    "                  0x0c: 'i',  # int (4 bytes)\n",
    "                  0x0d: 'f',  # float (4 bytes)\n",
    "                  0x0e: 'd'}  # double (8 bytes)\n",
    "\n",
    "    header = fd.read(4)\n",
    "    if len(header) != 4:\n",
    "        raise IdxDecodeError('Invalid IDX file, file empty or does not contain a full header.')\n",
    "\n",
    "    zeros, data_type, num_dimensions = struct.unpack('>HBB', header)\n",
    "\n",
    "    if zeros != 0:\n",
    "        raise IdxDecodeError('Invalid IDX file, file must start with two zero bytes. '\n",
    "                             'Found 0x%02x' % zeros)\n",
    "\n",
    "    try:\n",
    "        data_type = DATA_TYPES[data_type]\n",
    "    except KeyError:\n",
    "        raise IdxDecodeError('Unknown data type 0x%02x in IDX file' % data_type)\n",
    "\n",
    "    dimension_sizes = struct.unpack('>' + 'I' * num_dimensions,\n",
    "                                    fd.read(4 * num_dimensions))\n",
    "\n",
    "    data = array.array(data_type, fd.read())\n",
    "    data.byteswap()  # looks like array.array reads data as little endian\n",
    "\n",
    "    expected_items = functools.reduce(operator.mul, dimension_sizes)\n",
    "    if len(data) != expected_items:\n",
    "        raise IdxDecodeError('IDX file has wrong number of items. '\n",
    "                             'Expected: %d. Found: %d' % (expected_items, len(data)))\n",
    "\n",
    "    return np.array(data).reshape(dimension_sizes)\n",
    "\n",
    "\n",
    "def download_and_parse_mnist_file(fname, target_dir=None, force=False):\n",
    "    \"\"\"Download the IDX file named fname from the URL specified in dataset_url\n",
    "    and return it as a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        File name to download and parse\n",
    "\n",
    "    target_dir : str\n",
    "        Directory where to store the file\n",
    "\n",
    "    force : bool\n",
    "        Force downloading the file, if it already exists\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : numpy.ndarray\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "    \"\"\"\n",
    "    fname = download_file(fname, target_dir=target_dir, force=force)\n",
    "    fopen = gzip.open if os.path.splitext(fname)[1] == '.gz' else open\n",
    "    with fopen(fname, 'rb') as fd:\n",
    "        return parse_idx(fd)\n",
    "\n",
    "\n",
    "def train_images():\n",
    "    \"\"\"Return train images from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_images : numpy.ndarray\n",
    "        Numpy array with the images in the train MNIST database. The first\n",
    "        dimension indexes each sample, while the other two index rows and\n",
    "        columns of the image\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')\n",
    "\n",
    "\n",
    "def test_images():\n",
    "    \"\"\"Return test images from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_images : numpy.ndarray\n",
    "        Numpy array with the images in the train MNIST database. The first\n",
    "        dimension indexes each sample, while the other two index rows and\n",
    "        columns of the image\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('t10k-images-idx3-ubyte.gz')\n",
    "\n",
    "\n",
    "def train_labels():\n",
    "    \"\"\"Return train labels from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_labels : numpy.ndarray\n",
    "        Numpy array with the labels 0 to 9 in the train MNIST database.\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "def test_labels():\n",
    "    \"\"\"Return test labels from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_labels : numpy.ndarray\n",
    "        Numpy array with the labels 0 to 9 in the train MNIST database.\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "x_train = train_images()\n",
    "x_test = test_images()\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * \n",
    "                                x_train.shape[2]))\n",
    "\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * \n",
    "                                x_test.shape[2]))\n",
    "\n",
    "train_labels = train_labels()\n",
    "test_labels = test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca5 = PCA(n_components=5)\n",
    "pca5.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train5 = pca5.transform(x_train)\n",
    "x_test5 = pca5.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65249999999999997"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train5, train_labels)\n",
    "predictions = model.predict(x_test5)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=20, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca20 = PCA(n_components=20)\n",
    "pca20.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train20 = pca20.transform(x_train)\n",
    "x_test20 = pca20.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86829999999999996"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train20, train_labels)\n",
    "predictions = model.predict(x_test20)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x_train = StandardScaler().fit_transform(x_train)\n",
    "x_test = StandardScaler().fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cov_mat_train = np.cov(x_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eig_pairs.sort(key=lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_w = []\n",
    "for i in range(5):\n",
    "    matrix_w.append(eig_pairs[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 784)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_w = np.array(matrix_w)\n",
    "matrix_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_self = np.dot(x_train, matrix_w.T)\n",
    "pca_self_test = np.dot(x_test, matrix_w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64419999999999999"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(pca_self, train_labels)\n",
    "predictions = model.predict(pca_self_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_w = []\n",
    "for i in range(20):\n",
    "    matrix_w.append(eig_pairs[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_w = np.array(matrix_w)\n",
    "matrix_w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_self = np.dot(x_train, matrix_w.T)\n",
    "pca_self_test = np.dot(x_test, matrix_w.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85719999999999996"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(pca_self, train_labels)\n",
    "predictions = model.predict(pca_self_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
