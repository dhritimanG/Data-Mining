{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Mar 20 00:28:16 2018\n",
    "\n",
    "@author: dhritiman\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import functools\n",
    "import operator\n",
    "import gzip\n",
    "import struct\n",
    "import array\n",
    "import tempfile\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve  # py2\n",
    "try:\n",
    "    from urllib.parse import urljoin\n",
    "except ImportError:\n",
    "    from urlparse import urljoin\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the url can be changed by the users of the library (not a constant)\n",
    "datasets_url = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "\n",
    "class IdxDecodeError(ValueError):\n",
    "    \"\"\"Raised when an invalid idx file is parsed.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_file(fname, target_dir=None, force=False):\n",
    "    \"\"\"Download fname from the datasets_url, and save it to target_dir,\n",
    "    unless the file already exists, and force is False.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        Name of the file to download\n",
    "\n",
    "    target_dir : str\n",
    "        Directory where to store the file\n",
    "\n",
    "    force : bool\n",
    "        Force downloading the file, if it already exists\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    fname : str\n",
    "        Full path of the downloaded file\n",
    "    \"\"\"\n",
    "    if not target_dir:\n",
    "        target_dir = tempfile.gettempdir()\n",
    "    target_fname = os.path.join(target_dir, fname)\n",
    "\n",
    "    if force or not os.path.isfile(target_fname):\n",
    "        url = urljoin(datasets_url, fname)\n",
    "        urlretrieve(url, target_fname)\n",
    "\n",
    "    return target_fname\n",
    "\n",
    "\n",
    "def parse_idx(fd):\n",
    "    \"\"\"Parse an IDX file, and return it as a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fd : file\n",
    "        File descriptor of the IDX file to parse\n",
    "\n",
    "    endian : str\n",
    "        Byte order of the IDX file. See [1] for available options\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : numpy.ndarray\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "\n",
    "    1. https://docs.python.org/3/library/struct.html#byte-order-size-and-alignment\n",
    "    \"\"\"\n",
    "    DATA_TYPES = {0x08: 'B',  # unsigned byte\n",
    "                  0x09: 'b',  # signed byte\n",
    "                  0x0b: 'h',  # short (2 bytes)\n",
    "                  0x0c: 'i',  # int (4 bytes)\n",
    "                  0x0d: 'f',  # float (4 bytes)\n",
    "                  0x0e: 'd'}  # double (8 bytes)\n",
    "\n",
    "    header = fd.read(4)\n",
    "    if len(header) != 4:\n",
    "        raise IdxDecodeError('Invalid IDX file, file empty or does not contain a full header.')\n",
    "\n",
    "    zeros, data_type, num_dimensions = struct.unpack('>HBB', header)\n",
    "\n",
    "    if zeros != 0:\n",
    "        raise IdxDecodeError('Invalid IDX file, file must start with two zero bytes. '\n",
    "                             'Found 0x%02x' % zeros)\n",
    "\n",
    "    try:\n",
    "        data_type = DATA_TYPES[data_type]\n",
    "    except KeyError:\n",
    "        raise IdxDecodeError('Unknown data type 0x%02x in IDX file' % data_type)\n",
    "\n",
    "    dimension_sizes = struct.unpack('>' + 'I' * num_dimensions,\n",
    "                                    fd.read(4 * num_dimensions))\n",
    "\n",
    "    data = array.array(data_type, fd.read())\n",
    "    data.byteswap()  # looks like array.array reads data as little endian\n",
    "\n",
    "    expected_items = functools.reduce(operator.mul, dimension_sizes)\n",
    "    if len(data) != expected_items:\n",
    "        raise IdxDecodeError('IDX file has wrong number of items. '\n",
    "                             'Expected: %d. Found: %d' % (expected_items, len(data)))\n",
    "\n",
    "    return np.array(data).reshape(dimension_sizes)\n",
    "\n",
    "\n",
    "def download_and_parse_mnist_file(fname, target_dir=None, force=False):\n",
    "    \"\"\"Download the IDX file named fname from the URL specified in dataset_url\n",
    "    and return it as a numpy array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fname : str\n",
    "        File name to download and parse\n",
    "\n",
    "    target_dir : str\n",
    "        Directory where to store the file\n",
    "\n",
    "    force : bool\n",
    "        Force downloading the file, if it already exists\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : numpy.ndarray\n",
    "        Numpy array with the dimensions and the data in the IDX file\n",
    "    \"\"\"\n",
    "    fname = download_file(fname, target_dir=target_dir, force=force)\n",
    "    fopen = gzip.open if os.path.splitext(fname)[1] == '.gz' else open\n",
    "    with fopen(fname, 'rb') as fd:\n",
    "        return parse_idx(fd)\n",
    "\n",
    "\n",
    "def train_images():\n",
    "    \"\"\"Return train images from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_images : numpy.ndarray\n",
    "        Numpy array with the images in the train MNIST database. The first\n",
    "        dimension indexes each sample, while the other two index rows and\n",
    "        columns of the image\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('train-images-idx3-ubyte.gz')\n",
    "\n",
    "\n",
    "def test_images():\n",
    "    \"\"\"Return test images from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_images : numpy.ndarray\n",
    "        Numpy array with the images in the train MNIST database. The first\n",
    "        dimension indexes each sample, while the other two index rows and\n",
    "        columns of the image\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('t10k-images-idx3-ubyte.gz')\n",
    "\n",
    "\n",
    "def train_labels():\n",
    "    \"\"\"Return train labels from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_labels : numpy.ndarray\n",
    "        Numpy array with the labels 0 to 9 in the train MNIST database.\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "def test_labels():\n",
    "    \"\"\"Return test labels from Yann LeCun MNIST database as a numpy array.\n",
    "    Download the file, if not already found in the temporary directory of\n",
    "    the system.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    test_labels : numpy.ndarray\n",
    "        Numpy array with the labels 0 to 9 in the train MNIST database.\n",
    "    \"\"\"\n",
    "    return download_and_parse_mnist_file('t10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "x_train = train_images()\n",
    "x_test = test_images()\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1] * \n",
    "                                x_train.shape[2]))\n",
    "\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1] * \n",
    "                                x_test.shape[2]))\n",
    "\n",
    "#Normalize the data\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "train_labels = train_labels()\n",
    "test_labels = test_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92010000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, train_labels)\n",
    "predictions = model.predict(x_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92788333333333328"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(x_train)\n",
    "accuracy_score(train_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = np.sum(model.coef_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_lr = np.argpartition(coefficients, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_coeffs = coefficients[ind_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77997588,  0.78092778,  0.78402942,  0.80210089,  0.80449267,\n",
       "        0.81816997,  0.89438744,  0.87742605,  0.90145823,  0.92353411,\n",
       "        0.92661082,  1.56131923,  1.70069128,  1.44695792,  1.04207704,\n",
       "        1.49046195,  1.1380128 ,  1.63448667,  1.6267958 ,  1.12630273,\n",
       "        2.56200649,  1.85109873,  0.95514845,  1.13365936,  1.45140487,\n",
       "        1.31979968,  2.29837151,  1.32322886,  0.94883686,  1.33403185])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dec = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87870000000000004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MNIST DecTree\n",
    "model_dec.fit(x_train, train_labels)\n",
    "predictions = model_dec.predict(x_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model_dec.predict(x_train)\n",
    "accuracy_score(train_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 F-splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dec.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.argpartition(model_dec.feature_importances_, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_splits = model_dec.feature_importances_[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00670604,  0.00670949,  0.00927382,  0.00860532,  0.00950561,\n",
       "        0.01295473,  0.00780107,  0.00740432,  0.00708782,  0.0103048 ,\n",
       "        0.01256605,  0.00817836,  0.01125268,  0.00910799,  0.01301591,\n",
       "        0.01955284,  0.01658926,  0.02334537,  0.02014354,  0.04853667,\n",
       "        0.01831606,  0.01346989,  0.0150033 ,  0.04443238,  0.04421645,\n",
       "        0.02307007,  0.05409823,  0.02688075,  0.03858051,  0.03182818])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20 NG\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(newsgroups_train.data)\n",
    "vectors_train = vectorizer.transform(newsgroups_train.data)\n",
    "vectors_test = vectorizer.transform(newsgroups_test.data)\n",
    "\n",
    "# NG LABELS\n",
    "train_labels = newsgroups_train.target\n",
    "test_labels = newsgroups_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82793414763674988"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(vectors_train, train_labels)\n",
    "predictions = model.predict(vectors_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96986035000883863"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(vectors_train)\n",
    "accuracy_score(train_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 coeffients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = np.sum(model.coef_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_lr = np.argpartition(coefficients, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_coeffs = coefficients[ind_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70318708,  0.70561878,  0.70606958,  0.71529472,  0.74268857,\n",
       "        0.71634711,  0.70767552,  0.71112062,  0.74520355,  0.87297082,\n",
       "        0.74795028,  1.03302393,  0.84017614,  1.23718566,  0.81295133,\n",
       "        0.91476254,  1.17681965,  1.02881162,  0.94128184,  0.82367258,\n",
       "        0.98146202,  0.91139696,  0.98558677,  0.86566467,  0.95044618,\n",
       "        1.09672473,  0.92239842,  0.88301474,  0.77757021,  0.77505414])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dec = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55509824747742964"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dec.fit(vectors_train, train_labels)\n",
    "predictions = model_dec.predict(vectors_test)\n",
    "accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99991161392964467"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dec.fit(vectors_train, train_labels)\n",
    "predictions = model_dec.predict(vectors_train)\n",
    "accuracy_score(train_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 F-splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130107,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dec.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.argpartition(model_dec.feature_importances_, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_splits = model_dec.feature_importances_[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00543265,  0.00547868,  0.00565649,  0.00575063,  0.00615971,\n",
       "        0.00608869,  0.00583506,  0.00695991,  0.0069749 ,  0.00852913,\n",
       "        0.00844939,  0.00839107,  0.00792949,  0.00702591,  0.00808599,\n",
       "        0.00946531,  0.01507008,  0.02658513,  0.01080522,  0.02319633,\n",
       "        0.01073602,  0.01158107,  0.01871538,  0.01781211,  0.02389467,\n",
       "        0.0180159 ,  0.01846134,  0.02042067,  0.02441666,  0.01583442])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spambase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/dhritiman/Downloads/spambase/spambase.data', header=None)\n",
    "data.rename(columns={57:'is_spam'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam = data[data['is_spam'] == 1]\n",
    "ham = data[data['is_spam'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train, spam_test = train_test_split(spam, train_size=0.6)\n",
    "ham_train, ham_test = train_test_split(ham, train_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = ham_train.append(spam_train)\n",
    "y_train = X_train.pop('is_spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = ham_test.append(spam_test)\n",
    "y_test = X_test.pop('is_spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92779587404994568"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93258426966292129"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "accuracy_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = np.sum(model.coef_, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind_lr = np.argpartition(coefficients, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_coeffs = coefficients[ind_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  6.10015842e-04,   7.64033753e-03,   4.78501266e-02,\n",
       "         4.91755989e-02,   1.25024821e-01,   1.41810376e-01,\n",
       "         2.52784022e-01,   2.45924123e-01,   2.08716401e-01,\n",
       "         2.67375737e-01,   1.04832848e+00,   1.17343269e+00,\n",
       "         6.96163462e-01,   2.22948891e+00,   1.12743448e+00,\n",
       "         3.24934154e-01,   1.02273595e+00,   5.17089450e-01,\n",
       "         2.71743688e+00,   8.75819936e-01,   4.48013485e-01,\n",
       "         6.63966196e-01,   3.51080454e-01,   6.83660750e-01,\n",
       "         4.58605272e-01,   3.83681382e+00,   1.08413247e+00,\n",
       "         5.07790306e-01,   2.69082568e-01,   5.53922344e-01])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90228013029315957"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Train set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99963754983689745"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_train)\n",
    "accuracy_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 30 F-splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.argpartition(model.feature_importances_, -30)[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_splits = model.feature_importances_[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00286872,  0.00302832,  0.00303041,  0.0040096 ,  0.00422451,\n",
       "        0.00861683,  0.02021456,  0.03272419,  0.00579659,  0.01098553,\n",
       "        0.00570411,  0.00935   ,  0.01422141,  0.01017135,  0.00896798,\n",
       "        0.0583388 ,  0.00704576,  0.00757263,  0.02315709,  0.00634664,\n",
       "        0.10606537,  0.00551273,  0.00833663,  0.01955408,  0.35507874,\n",
       "        0.06738687,  0.00436786,  0.02714645,  0.11884535,  0.02092832])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
